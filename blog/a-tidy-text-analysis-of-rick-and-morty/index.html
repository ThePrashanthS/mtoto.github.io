<!DOCTYPE html>
<html lang="en-us">

<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="Coding with Data">

    
<title>


     A tidy text analysis of Rick and Morty 

</title>
<link rel="canonical" href="http://tamaszilagyi.com/blog/a-tidy-text-analysis-of-rick-and-morty/">


<script type="text/javascript">
    var baseURL = 'http:\/\/tamaszilagyi.com\/';
    var host = baseURL.substring(0, baseURL.length - 1).replace(/\//g, '');
    if ((host === window.location.host) && (window.location.protocol !== 'https:')) {
        window.location.protocol = 'https:';
    }
</script>




    <link rel="stylesheet" href="http://tamaszilagyi.com/css/vs.css">
    <script src="http://tamaszilagyi.com/js/highlight.pack.js"></script>
    <script>
  hljs.initHighlightingOnLoad();
    </script>







    
    <link rel="stylesheet" href="../../css/reset.css?t=1529436298">
    <link rel="stylesheet" href="../../css/main.css?t=1529436298">
    
        <link rel="stylesheet" href="../../css/override.css?t=1529436298">
    




<link rel="shortcut icon"

    href="../../img/leaf.ico"

>






</head>


<body lang="en">

<section class="header">
    <div class="container">
        <div class="content">
            
              <a href="../../"><img class="avatar" src="../../img/profile_pic.png" /></a>
            
            <a href="../../"><div class="name">Tamas Szilagyi</div></a>
            
              <h3 class="self-intro">Coding with Data</h3>
            
            <nav>
                <ul>
                    <a href="../../blog/"><li>Blog</li></a>
                    <a href="../../about/"><li>About</li></a>
                </ul>
            </nav>
        </div>
    </div>
</section>

<section class="icons">
    <div class="container">
        <div class="content">
            
        
            <a href="mailto:tszilagyi@outlook.com"><img class="icon" src="../../img/email.svg" alt="email" /></a>
        
            
        
            <a href="//linkedin.com/in/tszilagyi" target="_blank"><img class="icon" src="../../img/linkedin.svg" alt="linkedin" /></a>
        
            
        
            <a href="//twitter.com/tudosgar" target="_blank"><img class="icon" src="../../img/twitter.svg" alt="twitter" /></a>
        

        
            <a href="//github.com/mtoto" target="_blank"><img class="icon" src="../../img/github.svg" alt="github" /></a>
        
            
        
            <a href="//stackoverflow.com/users/4964651/mtoto?tab=profile" target="_blank"><img class="icon" src="../../img/so.svg" alt="stackoverflow" /></a>
        


        

        
            <a href="//soundcloud.com/tamas-szilagyi" target="_blank"><img class="icon" src="../../img/soundcloud.svg" alt="soundcloud" /></a>
        

        

       
        </div>
    </div>
</section>
    


<section class="main post non-narrow zero-top-spacing">
    <div class="container">
        <div class="content">
            <div class="front-matter">
                <div class="title-container">
                    <div class="page-heading">

    A tidy text analysis of Rick and Morty

</div>

                    <div class="initials"><a href="http://tamaszilagyi.com/"></a></div>
                </div>
                <div class="meta">
                    <div class="date" title="Sat Oct 7 2017 23:15:14 -0500">Oct 7, 2017</div>
                    <div class="reading-time"><div class="middot"></div>9 minutes read</div>
                </div>
            </div>
            <div class="markdown">
                <div class="figure">
<img src="http://i.imgur.com/a841k9g.gif" />

</div>
<style type="text/css">
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>
<div id="adventures-in-the-multiverse" class="section level2">
<h2>Adventures in the multiverse</h2>
<p>For those unfamiliar with the show, Rick and Morty is an animated series about the interuniversal exploits of a half-drunk mad scientist Rick, and his daft grandson Morty. Living under one roof with his daughter, Rick constantly drags his grandson Morty along for adventures into unusual worlds inhabited by surreal creatures. At first hesitant to accompany his eccentric granddad, Morty slowly grows into an indispensable sidekick. Using Rick’s portal gun, they leave the rest of their dysfunctional family at home, and travel through space and time.</p>
<p>Most episodes draw inspiration from or make fun of cult movies such as Back to the Future, A Nightmare on Elm Street, Inception and many other classics by the likes of John Carpenter or David Cronenberg. Besides the ruthless humor and over-the-top visual scenery, the show brilliantly builds independent sci-fi realms, going about their day-to-day according to their wacky rules.</p>
</div>
<div id="one-mans-weekend-project-another-mans-treasure" class="section level2">
<h2>One man’s weekend project, another man’s treasure</h2>
<p>After reading the book <a href="http://tidytextmining.com/">Tidy Text Mining</a> online, I have been wanting to try out some of the concepts outlined in the book, and the functions of the <a href="https://github.com/juliasilge/tidytext">accompanying package</a>, on an interesting dataset. So I was pretty stoked to find <a href="https://github.com/fkeck/subtools">Francois Keck’s <strong>subtools package</strong> on GitHub</a>, that allows for reading <em>.srt</em> files (the usual format for subtitles) straight into R. With season 3 of Rick and Morty coming to an end last week, the stars have finally aligned to roll up my sleeves and have some fun with text mining.</p>
<p>It is very easy to find English subtitles for pretty much anything on the Internet. With subtools, an entire series can be read with one command from the containing folder, <code>read.subtitles.serie()</code>. We convert the resulting MultiSubtitles object to a data.frame with a second command <code>subDataFrame()</code>.</p>
<pre class="r"><code>library(subtools)
a &lt;- read.subtitles.serie(dir = &quot;/series/rick and morty/&quot;)
df &lt;- subDataFrame(a)
str(df)</code></pre>
<pre><code>## Read: 3 seasons, 31 episodes</code></pre>
<pre><code>## &#39;data.frame&#39;:    16821 obs. of  8 variables:
##  $ ID          : chr  &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ Timecode.in : chr  &quot;00:00:02.445&quot; &quot;00:00:03.950&quot; &quot;00:00:05.890&quot; &quot;00:00:07.420&quot; ...
##  $ Timecode.out: chr  &quot;00:00:03.850&quot; &quot;00:00:05.765&quot; &quot;00:00:07.295&quot; &quot;00:00:08.925&quot; ...
##  $ Text        : chr  &quot;Morty, you got to... come on.&quot; &quot;- You got to come with me. - Rick, what&#39;s going on?&quot; &quot;I got a surprise for you, Morty.&quot; &quot;It&#39;s the middle of the night. What are you talking about?&quot; ...
##  $ season      : chr  &quot;Season_1&quot; &quot;Season_1&quot; &quot;Season_1&quot; &quot;Season_1&quot; ...
##  $ season_num  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ episode_num : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ serie       : chr  &quot;rick and morty&quot; &quot;rick and morty&quot; &quot;rick and morty&quot; &quot;rick and morty&quot; ...</code></pre>
<p>The <code>$Text</code> column contains the subtitle text, surrounded by additional variables for line id, timestamp, season and episode number. This is the structure preferred by the tidytext package, as it is by the rest of tidyverse.</p>
</div>
<div id="morty-you-got-tocome-on." class="section level2">
<h2><em>“Morty, you got to…come on.”</em></h2>
<p>Let’s start with the bread and butter of text mining, <em>term frequencies</em>. We split the text by word, exclude stop words,</p>
<pre class="r"><code>data(stop_words)
tidy_df &lt;- df %&gt;%
  unnest_tokens(word, Text) %&gt;%
  anti_join(stop_words)</code></pre>
<p>and aggregate and plot the top 10 words per season.</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)

tidy_df %&gt;% group_by(season) %&gt;%
        count(word, sort = TRUE) %&gt;%
        top_n(10) %&gt;%
        ggplot(aes(reorder(word,n), n, fill = season)) +
        geom_col() +
        coord_flip() +
        facet_wrap(~season, scales = &quot;free_y&quot;) +
        labs(x = NULL) +
        guides(fill = FALSE) +
        scale_fill_brewer(palette = &quot;Set1&quot;)</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/blog/2017/2017-10-07-tidyrick_files/figure-html/unnamed-chunk-6-1.png" />

</div>
<p>Both seasons are dominated by, well, Rick and Morty. The main characters are tirelessly addressing each other, talking one another either into or out of the mess they find themselves in. What stands out most is the absence of Rick’s daughter, Beth from the top 10 in all seasons. She’s perhaps the only sane person of the family, but then again, sanity doesn’t get too much airtime on this show.</p>
</div>
<div id="network-analysis-on-bi-grams" class="section level2">
<h2>Network analysis on bi-grams</h2>
<p>We can similarly get the number of times each <em>two words</em> appear, called <em>bi-grams</em>. Besides calculating summary statistics on bi-grams, we can now construct a network of words according to co-occurrence using <a href="https://cran.r-project.org/web/packages/igraph/index.html">igraph</a>, the go-to package for network analysis in R.</p>
<pre class="r"><code>library(tidyr)
library(igraph)

bigram_graph &lt;- df %&gt;%
  unnest_tokens(bigram, Text, token = &quot;ngrams&quot;, n = 2) %&gt;%
  separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;%
  filter(!word1 %in% stop_words$word) %&gt;%
  filter(!word2 %in% stop_words$word) %&gt;% 
  group_by(season) %&gt;%
  count(word1, word2, sort = TRUE) %&gt;%
  select(word1, word2, season, n) %&gt;%
  filter(n &gt; 2) %&gt;%
  graph_from_data_frame()</code></pre>
<pre><code>## Warning in graph_from_data_frame(.): In `d&#39; `NA&#39; elements were replaced
## with string &quot;NA&quot;</code></pre>
<pre class="r"><code>print(bigram_graph)</code></pre>
<pre><code>## IGRAPH 72a84d6 DN-- 311 283 -- 
## + attr: name (v/c), season (e/c), n (e/n)
## + edges from 72a84d6 (vertex names):
## [1] NA      -&gt;NA      NA      -&gt;NA      NA      -&gt;NA      tiny    -&gt;rick   
## [5] yeah    -&gt;yeah   
##  [ reached getOption(&quot;max.print&quot;) -- omitted 21 entries ]
## + ... omitted several edges</code></pre>
<p>This igraph object contains a directed network, where the vertices are the words and an edge exists between each that appear after one another more than twice. Representing the text as a graph, we can calculate things such as <a href="https://en.wikipedia.org/wiki/Centrality#Degree_centrality">degree centrality</a>, and plot the results.</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/blog/2017/2017-10-07-tidyrick_files/figure-html/unnamed-chunk-9-1.png" />

</div>
<p>Looking at the largest connected network, we arrive at the same conclusion as with term frequencies. Rick and Morty are the most important words. They are at the center of the network and so have the highest degree centrality scores.</p>
<p>Besides visualising the importance of words in our network, we can similarly differentiate between words that precede either Rick or Morty. These are all the 1st degree connections (words) that have an edge pointing towards the main characters, but aren’t shared among the them.</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/blog/2017/2017-10-07-tidyrick_files/figure-html/unnamed-chunk-10-1.png" />

</div>
<p>Looking at the red nodes, we recognize many of the things Rick throws at Morty: <em>“Relax Morty!…It’s science Morty!…Run Morty!”</em>. There is also a handful of words that precede both characters like <em>“Geez”, “Boy”</em> or <em>“God”</em>. All other words that are more than one degree away, are colored blue as out of range.</p>
</div>
<div id="tf-idf" class="section level2">
<h2>tf-idf</h2>
<p>Thus far we have looked at all words across seasons. But where do the seasons differ from each other? And can we summarise each season using a handful of topics? To answer the first question, text mining’s most notorious statistic <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"><strong>tf-idf</strong></a> comes to the rescue. It stands for <strong>term frequency - inverse document frequency</strong>. We take the word counts per season and multiply it by the <em>scaled inverse fraction of seasons that contain the word</em>. Simply put, we penalize words that are common across all seasons, and reward ones that are not. This way, we bring forth the words most typical of each season. Again the tidytext implementation is super easy.</p>
<pre class="r"><code>tf_idf_df &lt;- tidy_df %&gt;% 
        count(season, word, sort = TRUE) %&gt;%
        bind_tf_idf(word, season, n)</code></pre>
<p><img src="https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/blog/2017/2017-10-07-tidyrick_files/figure-html/unnamed-chunk-12-1.png" /> What we get back are the most important elements, characters, motives or places across episodes. I’m somewhat surprised that Mr. Meeseeks didn’t come in first though. I was sure as hell annoyed out of my mind after hearing it uttered for the 100th time during the episode <a href="https://en.wikipedia.org/wiki/Meeseeks_and_Destroy">Meeseeks and Destroy</a>. But then again, Mr Meeseeks does make a cameo in two other seasons, so that kind of torpedoes his chances for the first spot.</p>
</div>
<div id="topic-models" class="section level2">
<h2>Topic models</h2>
<p>Having seen the most unique words of the script by seasons, we will take our analysis one last step further and try to capture the gist of a the show using topic modeling. Broadly speaking, it’s an unsupervised classification method that tries to represent a document as a collection of topics. Here, I will take the classic <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation or shortly LDA</a> algorithm for a spin. The basic idea is that</p>
<blockquote>
<p>“…a topic is defined as a mixture over words where each word has a probability of belonging to a topic. And a document is a mixture over topics, meaning that a single document can be composed of multiple topics.”&quot;</p>
</blockquote>
<p>We could for example take season two, and tell <code>LDA()</code> that we want to compress 10 episodes into just 6 topics. To compensate for the omnipresence of the top words across episodes, I will exclude them for the purpose of clearer separation of topics.</p>
<pre class="r"><code>library(topicmodels)
popular_words &lt;- c(&quot;rick&quot;,&quot;morty&quot;, &quot;yeah&quot;,&quot;hey&quot;,
                   &quot;summer&quot;, &quot;jerry&quot;, &quot;uh&quot;, &quot;gonna&quot;)

episodes_dtm &lt;- tidy_df %&gt;% filter(season_num == 2 &amp; !word %in% popular_words) %&gt;%
        group_by(episode_num) %&gt;%
        count(word, sort = TRUE) %&gt;%
        cast_dtm(episode_num, word, n) 

episodes_lda &lt;- LDA(episodes_dtm, k = 6, control = list(seed = 1234))</code></pre>
<p>After <code>tidy()</code>ing the results, we can plot the top 10 words that contribute (<em>beta</em>) to most to each topic.</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/blog/2017/2017-10-07-tidyrick_files/figure-html/unnamed-chunk-14-1.png" />

</div>
<p>There’s definitely a few topics that contain multiple elements of a particular episode. Take for example <strong>topic 1</strong>. It includes “<em>Roy</em>”, the name of the videogame Morty plays in the same episode “<em>Fart</em>” appears, a gaseous creature kept under locks by aliens. Or <strong>topic 5</strong>, which probably relates to the episode where Rick visits his old lover “<em>Unity</em>”. It further contains words as “<em>remember</em>” and “<em>memories</em>”. The episode ends with Unity repeating “I want it <em>real</em>”.</p>
<p>Not only can we examine the <strong>word per topic probabilities</strong>, we can also plot <strong>the topic per document probabilities</strong>, or <em>gamma</em> values. This lets us see what topic belongs to what episode.</p>
<pre class="r"><code>tidy(episodes_lda, matrix = &quot;gamma&quot;) %&gt;%
        inner_join(titles) %&gt;%
        ggplot(aes(factor(topic), gamma)) +
        geom_boxplot() +
        facet_wrap(~ title) +
        ggtitle(&quot;Dominant Topics per Episode&quot;)</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/blog/2017/2017-10-07-tidyrick_files/figure-html/unnamed-chunk-16-1.png" />

</div>
<p>Our previous assumptions are confirmed, the first topic does belong to the episode <em>Mortynight Run</em> as does the fifth topic to <em>Auto-Erotic Assimilation</em>. It is important to note that the results strongly depend on the number of topics supplied to <code>LDA()</code>, so inevitably, some experimentation is required to arrive at meaningful results.</p>
</div>
<div id="final-thoughts" class="section level2">
<h2>Final thoughts</h2>
<p>I ran through some very interesting concepts fairly quickly in this post. I owe much of it to the tidytext package. With very little coding, we can mine a tremendous amount of insights from textual data. And I have just scrachted the surface of what’s possible. The seamless integration with the tidyverse, as with igraph and topicmodels does make a huge difference.</p>
<p>Nonetheless, text mining is a complex topic and when arriving at more advanced material, <a href="https://github.com/trinker/topicmodels_learning">further reading</a> on the inner workings of these algorithms might come in handy for effective use. The full <a href="https://github.com/mtoto/mtoto.github.io/tree/master/data/2017-10-07-tidyrick/rick%20and%20morty">data</a> and <a href="https://github.com/mtoto/mtoto.github.io/blob/master/blog/2017/2017-10-07-tidyrick.Rmd">code</a> for this post is available as usual on my Github.</p>
</div>

                <br>
                <p><a href="../../blog/">Back to posts</a></p>
            </div>
            <br>
            <div class="disqus">
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'tamas-blog';
    var disqus_identifier = 'http:\/\/tamaszilagyi.com\/blog\/a-tidy-text-analysis-of-rick-and-morty\/';
    var disqus_title = 'A tidy text analysis of Rick and Morty';
    var disqus_url = 'http:\/\/tamaszilagyi.com\/blog\/a-tidy-text-analysis-of-rick-and-morty\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
            </div>
        </div>
    </div>
</section>

   <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    });
    </script>
    <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>



<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-97386385-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>



  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js"></script>
  
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/languages/r.min.js"></script>
  

  <script type="text/javascript">
    hljs.initHighlightingOnLoad();
  </script>






<link rel="stylesheet" href="http://tamaszilagyi.com//css/vs.css">
<script src="http://tamaszilagyi.com/js/highlight.pack.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>



